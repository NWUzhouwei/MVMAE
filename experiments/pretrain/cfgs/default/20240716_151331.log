2024-07-16 15:13:31,090 - pretrain - INFO - Copy the Config file from cfgs/pretrain.yaml to ./experiments/pretrain/cfgs/default/config.yaml
2024-07-16 15:13:31,090 - pretrain - INFO - args.config : cfgs/pretrain.yaml
2024-07-16 15:13:31,090 - pretrain - INFO - args.launcher : none
2024-07-16 15:13:31,090 - pretrain - INFO - args.local_rank : 0
2024-07-16 15:13:31,090 - pretrain - INFO - args.num_workers : 4
2024-07-16 15:13:31,090 - pretrain - INFO - args.seed : 0
2024-07-16 15:13:31,090 - pretrain - INFO - args.deterministic : False
2024-07-16 15:13:31,090 - pretrain - INFO - args.sync_bn : False
2024-07-16 15:13:31,090 - pretrain - INFO - args.exp_name : default
2024-07-16 15:13:31,090 - pretrain - INFO - args.loss : cd1
2024-07-16 15:13:31,090 - pretrain - INFO - args.start_ckpts : None
2024-07-16 15:13:31,090 - pretrain - INFO - args.ckpts : None
2024-07-16 15:13:31,091 - pretrain - INFO - args.val_freq : 1
2024-07-16 15:13:31,091 - pretrain - INFO - args.vote : False
2024-07-16 15:13:31,091 - pretrain - INFO - args.resume : False
2024-07-16 15:13:31,091 - pretrain - INFO - args.test : False
2024-07-16 15:13:31,091 - pretrain - INFO - args.finetune_model : False
2024-07-16 15:13:31,091 - pretrain - INFO - args.scratch_model : False
2024-07-16 15:13:31,091 - pretrain - INFO - args.mode : None
2024-07-16 15:13:31,091 - pretrain - INFO - args.way : -1
2024-07-16 15:13:31,091 - pretrain - INFO - args.shot : -1
2024-07-16 15:13:31,091 - pretrain - INFO - args.fold : -1
2024-07-16 15:13:31,091 - pretrain - INFO - args.start_epoch : 0
2024-07-16 15:13:31,091 - pretrain - INFO - args.output_dir : /home/liu/Model/MV-Point-MAE/experiments/pretrain/cfgs/txt
2024-07-16 15:13:31,091 - pretrain - INFO - args.dist_on_itp : False
2024-07-16 15:13:31,091 - pretrain - INFO - args.accum_iter : 1
2024-07-16 15:13:31,091 - pretrain - INFO - args.warmup_epochs : 40
2024-07-16 15:13:31,091 - pretrain - INFO - args.log_dir : /home/liu/Model/MV-Point-MAE/experiments/pretrain/cfgs/default
2024-07-16 15:13:31,091 - pretrain - INFO - args.lr : None
2024-07-16 15:13:31,091 - pretrain - INFO - args.min_lr : 0.0
2024-07-16 15:13:31,091 - pretrain - INFO - args.blr : 0.001
2024-07-16 15:13:31,091 - pretrain - INFO - args.experiment_path : ./experiments/pretrain/cfgs/default
2024-07-16 15:13:31,091 - pretrain - INFO - args.tfboard_path : ./experiments/pretrain/cfgs/TFBoard/default
2024-07-16 15:13:31,091 - pretrain - INFO - args.log_name : pretrain
2024-07-16 15:13:31,091 - pretrain - INFO - args.use_gpu : True
2024-07-16 15:13:31,091 - pretrain - INFO - args.distributed : False
2024-07-16 15:13:31,091 - pretrain - INFO - config.optimizer = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.optimizer.type : AdamW
2024-07-16 15:13:31,091 - pretrain - INFO - config.optimizer.kwargs = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.optimizer.kwargs.lr : 0.001
2024-07-16 15:13:31,091 - pretrain - INFO - config.optimizer.kwargs.weight_decay : 0.05
2024-07-16 15:13:31,091 - pretrain - INFO - config.scheduler = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.scheduler.type : CosLR
2024-07-16 15:13:31,091 - pretrain - INFO - config.scheduler.kwargs = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.scheduler.kwargs.epochs : 300
2024-07-16 15:13:31,091 - pretrain - INFO - config.scheduler.kwargs.initial_epochs : 10
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train._base_ = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train._base_.NAME : ShapeNet
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train._base_.DATA_PATH : /home/liu/dataSet/ShapeNet55_s_point_8_256
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train._base_.N_POINTS : 8192
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train._base_.PC_PATH : /home/liu/dataSet/ShapeNet55_s_point_8_256
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train.others = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train.others.subset : train
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train.others.npoints : 8192
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.train.others.bs : 24
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val._base_ = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val._base_.NAME : ShapeNet
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val._base_.DATA_PATH : /home/liu/dataSet/ShapeNet55_s_point_8_256
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val._base_.N_POINTS : 8192
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val._base_.PC_PATH : /home/liu/dataSet/ShapeNet55_s_point_8_256
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val.others = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val.others.subset : test
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val.others.npoints : 8192
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.val.others.bs : 24
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.test = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.test._base_ = edict()
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.test._base_.NAME : ShapeNet
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.test._base_.DATA_PATH : /home/liu/dataSet/ShapeNet55_s_point_8_256
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.test._base_.N_POINTS : 8192
2024-07-16 15:13:31,091 - pretrain - INFO - config.dataset.test._base_.PC_PATH : /home/liu/dataSet/ShapeNet55_s_point_8_256
2024-07-16 15:13:31,092 - pretrain - INFO - config.dataset.test.others = edict()
2024-07-16 15:13:31,092 - pretrain - INFO - config.dataset.test.others.subset : test
2024-07-16 15:13:31,092 - pretrain - INFO - config.dataset.test.others.npoints : 8192
2024-07-16 15:13:31,092 - pretrain - INFO - config.dataset.test.others.bs : 24
2024-07-16 15:13:31,092 - pretrain - INFO - config.model = edict()
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.NAME : Point_MAE
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.group_size : 32
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.num_group : 64
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.loss : cdl2
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config = edict()
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.mask_ratio : 0.6
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.mask_type : rand
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.trans_dim : 384
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.encoder_dims : 384
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.depth : 12
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.drop_path_rate : 0.1
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.num_heads : 6
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.decoder_depth : 4
2024-07-16 15:13:31,092 - pretrain - INFO - config.model.transformer_config.decoder_num_heads : 6
2024-07-16 15:13:31,092 - pretrain - INFO - config.npoints : 1024
2024-07-16 15:13:31,092 - pretrain - INFO - config.total_bs : 24
2024-07-16 15:13:31,092 - pretrain - INFO - config.step_per_update : 1
2024-07-16 15:13:31,092 - pretrain - INFO - config.max_epoch : 300
2024-07-16 15:13:31,092 - pretrain - INFO - Distributed training: False
2024-07-16 15:13:31,092 - pretrain - INFO - Set random seed to 0, deterministic: False
